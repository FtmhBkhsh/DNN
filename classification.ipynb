{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### import libraries\n"
      ],
      "metadata": {
        "id": "Wkhv8AbK3tH8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "TY1C95z5TIGT"
      },
      "outputs": [],
      "source": [
        "import torch #import torch library\n",
        "import torch.nn as nn #import torch neural network library\n",
        "import torch.nn.functional as F #import functional neural network module\n",
        "import torch.optim as optim #import optimizer neural network module\n",
        "from torch.autograd import Variable #import variable that connect to automatic differentiation\n",
        "from torchvision import datasets, transforms #import torchvision for datasets and transform\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### variables"
      ],
      "metadata": {
        "id": "0q0pkpf-4J-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate=0.01"
      ],
      "metadata": {
        "id": "uhL5pgrpn-t7"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### DNN function\n"
      ],
      "metadata": {
        "id": "gC_0IkcH4X7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DNN, self).__init__() #load super class for training data\n",
        "    self.fc1 = nn.Linear(784, 600)\n",
        "    self.fc2 = nn.Linear(600, 450)\n",
        "    self.fc3 = nn.Linear(450, 200)\n",
        "    self.fc4 = nn.Linear(200, 100)\n",
        "    self.fc5 = nn.Linear(100, 50)\n",
        "    self.fc6 = nn.Linear(50, 20)\n",
        "    self.fc7 = nn.Linear(20, 10)\n",
        "    self.relu = nn.ReLU()\n",
        "\t\n",
        "  def forward(self, x): #feed forward\n",
        "    layer1 = x.view(-1, 784) #make it flat from 0 - 320\n",
        "    layer2 = self.relu(self.fc1(layer1)) #layer2 = layer1 -> fc1 -> relu\n",
        "    layer3 = self.relu(self.fc2(layer2)) #layer3 = layer2 -> fc2 -> relu\n",
        "    layer4 = self.relu(self.fc3(layer3)) #layer4 = layer3 -> fc3 -> relu\n",
        "    layer5 = self.relu(self.fc3(layer3)) #layer5 = layer4 -> fc5 -> relu\n",
        "    layer6 = self.relu(self.fc3(layer3)) #layer6 = layer5 -> fc6 -> relu\n",
        "    layer7 = self.relu(self.fc3(layer3)) #layer7 = layer6 -> fc7 -> relu\n",
        "\n",
        "    return F.log_softmax(layer7, -1) #softmax activation to layer4"
      ],
      "metadata": {
        "id": "fSr3jidvUjX5"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### load MNIST dataset"
      ],
      "metadata": {
        "id": "6d5csWRe4fFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "  def read(self):\n",
        "   learning_rate = 0.001 \n",
        "   train_dataset = torchvision.datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
        "   validation_dataset = torchvision.datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())\n",
        "   train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "   validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=batch_size,shuffle=False)\n",
        "   return train_loader, validation_loader"
      ],
      "metadata": {
        "id": "1YnkVvFiU_Dm"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader,validation_loader = Dataset().read()\n",
        "print(len(train_loader))\n",
        "print(len(validation_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf4rZIUcmGW2",
        "outputId": "bfbc6e32-bfe0-40de-8a63-1922f06a2125"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### create model and choose optimizer"
      ],
      "metadata": {
        "id": "jDawsr2D4woh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DNN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "lENhRT6M4s7q"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train"
      ],
      "metadata": {
        "id": "Z6lY3kx64vpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(epochs): # train epoch = 10\n",
        "\t\tmodel.train() #training\n",
        "\t\tfor batch_idx, (data, label) in enumerate(train_loader): #enumerate train_loader per batch-> index, (data, label) ex: 0, (img1, 4)... 1, (img2, 2)\n",
        "\t\t\tdata, label = Variable(data), Variable(label) #create torch variable and enter each data and label into it\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\toutput = model(data) #enter data into model, save in output\n",
        "\t\t\ttrain_loss = F.nll_loss(output, label) #nll = negative log likehood loss between output and label. it useful for classification problem with n class\n",
        "\t\t\ttrain_loss.backward() #compute gradient\n",
        "\t\t\toptimizer.step() #update weight\n",
        "\t\t\tif batch_idx % 10 == 0: #display step\n",
        "\t\t\t\tprint('Train Epochs: {}, Loss: {:.6f} '.format(epoch, train_loss.data )) #print\n",
        "\t\tmodel.eval() #evaluation\n",
        "\t\ttest_loss = 0\n",
        "\t\tcorrect = 0\n",
        "    #evaluation\n",
        "\t\tfor data, label in validation_loader: #separate data and label\n",
        "\t\t\tdata, label = Variable(data,volatile=True), Variable(label) #create torch variable and enter data and label into it\n",
        "\t\t\toutput = model(data) #enter data into model, save in output\n",
        "\t\t\ttest_loss += F.nll_loss(output, label, size_average=False).data #\n",
        "\t\t\tpred = output.data.max(1, keepdim=True)[1] #prediction result\n",
        "\t\t\tcorrect += pred.eq(label.data.view_as(pred)).cpu().sum() #if label=pred then correct++\n",
        "\t\ttest_loss /= len(validation_loader.dataset) #compute test loss\n",
        "\t\tprint('\\nAverage Loss: {:.4f}, Accuracy: {:.0f}'.format(test_loss,  100. * correct / len(validation_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWFdVGCAVCC5",
        "outputId": "c94f2e6e-7413-4aa8-f836-f1b26ccfa3e7"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epochs: 0, Loss: 5.297371 \n",
            "Train Epochs: 0, Loss: 2.494075 \n",
            "Train Epochs: 0, Loss: 1.912421 \n",
            "Train Epochs: 0, Loss: 1.817142 \n",
            "Train Epochs: 0, Loss: 1.792770 \n",
            "Train Epochs: 0, Loss: 1.630574 \n",
            "Train Epochs: 0, Loss: 1.479974 \n",
            "Train Epochs: 0, Loss: 1.435507 \n",
            "Train Epochs: 0, Loss: 1.440165 \n",
            "Train Epochs: 0, Loss: 1.928349 \n",
            "Train Epochs: 0, Loss: 1.330401 \n",
            "Train Epochs: 0, Loss: 1.484985 \n",
            "Train Epochs: 0, Loss: 1.038338 \n",
            "Train Epochs: 0, Loss: 1.452853 \n",
            "Train Epochs: 0, Loss: 1.039150 \n",
            "Train Epochs: 0, Loss: 1.441702 \n",
            "Train Epochs: 0, Loss: 1.737313 \n",
            "Train Epochs: 0, Loss: 0.972874 \n",
            "Train Epochs: 0, Loss: 0.738411 \n",
            "Train Epochs: 0, Loss: 0.267157 \n",
            "Train Epochs: 0, Loss: 0.267436 \n",
            "Train Epochs: 0, Loss: 0.384720 \n",
            "Train Epochs: 0, Loss: 0.141786 \n",
            "Train Epochs: 0, Loss: 0.128303 \n",
            "Train Epochs: 0, Loss: 0.240540 \n",
            "Train Epochs: 0, Loss: 0.222658 \n",
            "Train Epochs: 0, Loss: 0.436790 \n",
            "Train Epochs: 0, Loss: 0.253476 \n",
            "Train Epochs: 0, Loss: 0.202689 \n",
            "Train Epochs: 0, Loss: 0.202489 \n",
            "Train Epochs: 0, Loss: 0.390062 \n",
            "Train Epochs: 0, Loss: 0.202883 \n",
            "Train Epochs: 0, Loss: 0.177200 \n",
            "Train Epochs: 0, Loss: 0.132804 \n",
            "Train Epochs: 0, Loss: 0.243213 \n",
            "Train Epochs: 0, Loss: 0.184113 \n",
            "Train Epochs: 0, Loss: 0.197241 \n",
            "Train Epochs: 0, Loss: 0.037865 \n",
            "Train Epochs: 0, Loss: 0.211266 \n",
            "Train Epochs: 0, Loss: 0.260401 \n",
            "Train Epochs: 0, Loss: 0.113464 \n",
            "Train Epochs: 0, Loss: 0.086812 \n",
            "Train Epochs: 0, Loss: 0.352924 \n",
            "Train Epochs: 0, Loss: 0.074693 \n",
            "Train Epochs: 0, Loss: 0.250472 \n",
            "Train Epochs: 0, Loss: 0.176070 \n",
            "Train Epochs: 0, Loss: 0.186942 \n",
            "Train Epochs: 0, Loss: 0.504651 \n",
            "Train Epochs: 0, Loss: 0.220103 \n",
            "Train Epochs: 0, Loss: 0.269088 \n",
            "Train Epochs: 0, Loss: 0.362920 \n",
            "Train Epochs: 0, Loss: 0.221620 \n",
            "Train Epochs: 0, Loss: 0.133511 \n",
            "Train Epochs: 0, Loss: 0.166241 \n",
            "Train Epochs: 0, Loss: 0.238874 \n",
            "Train Epochs: 0, Loss: 0.161419 \n",
            "Train Epochs: 0, Loss: 0.115102 \n",
            "Train Epochs: 0, Loss: 0.301350 \n",
            "Train Epochs: 0, Loss: 0.107318 \n",
            "Train Epochs: 0, Loss: 0.275111 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Loss: 0.1613, Accuracy: 95\n",
            "Train Epochs: 1, Loss: 0.139795 \n",
            "Train Epochs: 1, Loss: 0.281211 \n",
            "Train Epochs: 1, Loss: 0.097513 \n",
            "Train Epochs: 1, Loss: 0.120148 \n",
            "Train Epochs: 1, Loss: 0.082996 \n",
            "Train Epochs: 1, Loss: 0.289305 \n",
            "Train Epochs: 1, Loss: 0.219148 \n",
            "Train Epochs: 1, Loss: 0.274213 \n",
            "Train Epochs: 1, Loss: 0.100824 \n",
            "Train Epochs: 1, Loss: 0.070135 \n",
            "Train Epochs: 1, Loss: 0.144091 \n",
            "Train Epochs: 1, Loss: 0.211357 \n",
            "Train Epochs: 1, Loss: 0.047043 \n",
            "Train Epochs: 1, Loss: 0.203002 \n",
            "Train Epochs: 1, Loss: 0.176305 \n",
            "Train Epochs: 1, Loss: 0.226544 \n",
            "Train Epochs: 1, Loss: 0.316829 \n",
            "Train Epochs: 1, Loss: 0.051196 \n",
            "Train Epochs: 1, Loss: 0.103002 \n",
            "Train Epochs: 1, Loss: 0.208443 \n",
            "Train Epochs: 1, Loss: 0.123128 \n",
            "Train Epochs: 1, Loss: 0.122795 \n",
            "Train Epochs: 1, Loss: 0.079565 \n",
            "Train Epochs: 1, Loss: 0.241435 \n",
            "Train Epochs: 1, Loss: 0.140227 \n",
            "Train Epochs: 1, Loss: 0.165299 \n",
            "Train Epochs: 1, Loss: 0.203843 \n",
            "Train Epochs: 1, Loss: 0.332744 \n",
            "Train Epochs: 1, Loss: 0.127916 \n",
            "Train Epochs: 1, Loss: 0.142615 \n",
            "Train Epochs: 1, Loss: 0.275764 \n",
            "Train Epochs: 1, Loss: 0.162770 \n",
            "Train Epochs: 1, Loss: 0.179014 \n",
            "Train Epochs: 1, Loss: 0.102515 \n",
            "Train Epochs: 1, Loss: 0.138336 \n",
            "Train Epochs: 1, Loss: 0.162515 \n",
            "Train Epochs: 1, Loss: 0.170086 \n",
            "Train Epochs: 1, Loss: 0.121532 \n",
            "Train Epochs: 1, Loss: 0.231842 \n",
            "Train Epochs: 1, Loss: 0.138402 \n",
            "Train Epochs: 1, Loss: 0.133917 \n",
            "Train Epochs: 1, Loss: 0.245142 \n",
            "Train Epochs: 1, Loss: 0.096318 \n",
            "Train Epochs: 1, Loss: 0.279374 \n",
            "Train Epochs: 1, Loss: 0.073564 \n",
            "Train Epochs: 1, Loss: 0.180449 \n",
            "Train Epochs: 1, Loss: 0.100975 \n",
            "Train Epochs: 1, Loss: 0.067784 \n",
            "Train Epochs: 1, Loss: 0.115272 \n",
            "Train Epochs: 1, Loss: 0.327519 \n",
            "Train Epochs: 1, Loss: 0.100077 \n",
            "Train Epochs: 1, Loss: 0.169557 \n",
            "Train Epochs: 1, Loss: 0.199895 \n",
            "Train Epochs: 1, Loss: 0.338276 \n",
            "Train Epochs: 1, Loss: 0.124440 \n",
            "Train Epochs: 1, Loss: 0.109152 \n",
            "Train Epochs: 1, Loss: 0.070819 \n",
            "Train Epochs: 1, Loss: 0.071356 \n",
            "Train Epochs: 1, Loss: 0.195113 \n",
            "Train Epochs: 1, Loss: 0.139829 \n",
            "\n",
            "Average Loss: 0.1526, Accuracy: 96\n",
            "Train Epochs: 2, Loss: 0.018514 \n",
            "Train Epochs: 2, Loss: 0.024206 \n",
            "Train Epochs: 2, Loss: 0.435769 \n",
            "Train Epochs: 2, Loss: 0.241386 \n",
            "Train Epochs: 2, Loss: 0.323638 \n",
            "Train Epochs: 2, Loss: 0.134733 \n",
            "Train Epochs: 2, Loss: 0.022145 \n",
            "Train Epochs: 2, Loss: 0.189349 \n",
            "Train Epochs: 2, Loss: 0.061908 \n",
            "Train Epochs: 2, Loss: 0.052595 \n",
            "Train Epochs: 2, Loss: 0.288243 \n",
            "Train Epochs: 2, Loss: 0.081045 \n",
            "Train Epochs: 2, Loss: 0.045540 \n",
            "Train Epochs: 2, Loss: 0.115189 \n",
            "Train Epochs: 2, Loss: 0.091347 \n",
            "Train Epochs: 2, Loss: 0.192861 \n",
            "Train Epochs: 2, Loss: 0.052615 \n",
            "Train Epochs: 2, Loss: 0.173011 \n",
            "Train Epochs: 2, Loss: 0.169560 \n",
            "Train Epochs: 2, Loss: 0.208916 \n",
            "Train Epochs: 2, Loss: 0.082029 \n",
            "Train Epochs: 2, Loss: 0.042677 \n",
            "Train Epochs: 2, Loss: 0.105714 \n",
            "Train Epochs: 2, Loss: 0.147672 \n",
            "Train Epochs: 2, Loss: 0.062199 \n",
            "Train Epochs: 2, Loss: 0.284919 \n",
            "Train Epochs: 2, Loss: 0.223467 \n",
            "Train Epochs: 2, Loss: 0.175470 \n",
            "Train Epochs: 2, Loss: 0.035072 \n",
            "Train Epochs: 2, Loss: 0.097522 \n",
            "Train Epochs: 2, Loss: 0.348247 \n",
            "Train Epochs: 2, Loss: 0.096591 \n",
            "Train Epochs: 2, Loss: 0.109171 \n",
            "Train Epochs: 2, Loss: 0.067985 \n",
            "Train Epochs: 2, Loss: 0.062616 \n",
            "Train Epochs: 2, Loss: 0.087645 \n",
            "Train Epochs: 2, Loss: 0.337195 \n",
            "Train Epochs: 2, Loss: 0.099293 \n",
            "Train Epochs: 2, Loss: 0.216091 \n",
            "Train Epochs: 2, Loss: 0.085217 \n",
            "Train Epochs: 2, Loss: 0.025143 \n",
            "Train Epochs: 2, Loss: 0.337954 \n",
            "Train Epochs: 2, Loss: 0.093114 \n",
            "Train Epochs: 2, Loss: 0.163252 \n",
            "Train Epochs: 2, Loss: 0.152324 \n",
            "Train Epochs: 2, Loss: 0.050216 \n",
            "Train Epochs: 2, Loss: 0.255482 \n",
            "Train Epochs: 2, Loss: 0.087662 \n",
            "Train Epochs: 2, Loss: 0.114926 \n",
            "Train Epochs: 2, Loss: 0.212373 \n",
            "Train Epochs: 2, Loss: 0.096444 \n",
            "Train Epochs: 2, Loss: 0.083772 \n",
            "Train Epochs: 2, Loss: 0.089803 \n",
            "Train Epochs: 2, Loss: 0.127640 \n",
            "Train Epochs: 2, Loss: 0.037496 \n",
            "Train Epochs: 2, Loss: 0.034671 \n",
            "Train Epochs: 2, Loss: 0.117943 \n",
            "Train Epochs: 2, Loss: 0.053298 \n",
            "Train Epochs: 2, Loss: 0.082624 \n",
            "Train Epochs: 2, Loss: 0.125393 \n",
            "\n",
            "Average Loss: 0.1634, Accuracy: 96\n",
            "Train Epochs: 3, Loss: 0.157672 \n",
            "Train Epochs: 3, Loss: 0.112916 \n",
            "Train Epochs: 3, Loss: 0.126552 \n",
            "Train Epochs: 3, Loss: 0.123577 \n",
            "Train Epochs: 3, Loss: 0.245381 \n",
            "Train Epochs: 3, Loss: 0.116819 \n",
            "Train Epochs: 3, Loss: 0.171190 \n",
            "Train Epochs: 3, Loss: 0.150318 \n",
            "Train Epochs: 3, Loss: 0.183009 \n",
            "Train Epochs: 3, Loss: 0.112288 \n",
            "Train Epochs: 3, Loss: 0.168646 \n",
            "Train Epochs: 3, Loss: 0.127278 \n",
            "Train Epochs: 3, Loss: 0.115255 \n",
            "Train Epochs: 3, Loss: 0.066968 \n",
            "Train Epochs: 3, Loss: 0.109318 \n",
            "Train Epochs: 3, Loss: 0.104630 \n",
            "Train Epochs: 3, Loss: 0.059272 \n",
            "Train Epochs: 3, Loss: 0.143613 \n",
            "Train Epochs: 3, Loss: 0.104652 \n",
            "Train Epochs: 3, Loss: 0.256541 \n",
            "Train Epochs: 3, Loss: 0.056398 \n",
            "Train Epochs: 3, Loss: 0.106977 \n",
            "Train Epochs: 3, Loss: 0.142227 \n",
            "Train Epochs: 3, Loss: 0.064420 \n",
            "Train Epochs: 3, Loss: 0.168792 \n",
            "Train Epochs: 3, Loss: 0.253110 \n",
            "Train Epochs: 3, Loss: 0.113667 \n",
            "Train Epochs: 3, Loss: 0.015283 \n",
            "Train Epochs: 3, Loss: 0.044545 \n",
            "Train Epochs: 3, Loss: 0.081401 \n",
            "Train Epochs: 3, Loss: 0.045947 \n",
            "Train Epochs: 3, Loss: 0.099665 \n",
            "Train Epochs: 3, Loss: 0.081041 \n",
            "Train Epochs: 3, Loss: 0.107852 \n",
            "Train Epochs: 3, Loss: 0.152783 \n",
            "Train Epochs: 3, Loss: 0.192092 \n",
            "Train Epochs: 3, Loss: 0.361456 \n",
            "Train Epochs: 3, Loss: 0.010517 \n",
            "Train Epochs: 3, Loss: 0.133126 \n",
            "Train Epochs: 3, Loss: 0.150696 \n",
            "Train Epochs: 3, Loss: 0.127991 \n",
            "Train Epochs: 3, Loss: 0.038224 \n",
            "Train Epochs: 3, Loss: 0.052871 \n",
            "Train Epochs: 3, Loss: 0.222313 \n",
            "Train Epochs: 3, Loss: 0.268558 \n",
            "Train Epochs: 3, Loss: 0.199799 \n",
            "Train Epochs: 3, Loss: 0.042546 \n",
            "Train Epochs: 3, Loss: 0.083627 \n",
            "Train Epochs: 3, Loss: 0.216940 \n",
            "Train Epochs: 3, Loss: 0.124320 \n",
            "Train Epochs: 3, Loss: 0.036855 \n",
            "Train Epochs: 3, Loss: 0.141852 \n",
            "Train Epochs: 3, Loss: 0.178036 \n",
            "Train Epochs: 3, Loss: 0.036255 \n",
            "Train Epochs: 3, Loss: 0.112064 \n",
            "Train Epochs: 3, Loss: 0.056337 \n",
            "Train Epochs: 3, Loss: 0.094235 \n",
            "Train Epochs: 3, Loss: 0.080420 \n",
            "Train Epochs: 3, Loss: 0.045223 \n",
            "Train Epochs: 3, Loss: 0.141826 \n",
            "\n",
            "Average Loss: 0.1558, Accuracy: 96\n",
            "Train Epochs: 4, Loss: 0.077158 \n",
            "Train Epochs: 4, Loss: 0.110350 \n",
            "Train Epochs: 4, Loss: 0.116437 \n",
            "Train Epochs: 4, Loss: 0.165186 \n",
            "Train Epochs: 4, Loss: 0.166601 \n",
            "Train Epochs: 4, Loss: 0.020390 \n",
            "Train Epochs: 4, Loss: 0.247226 \n",
            "Train Epochs: 4, Loss: 0.174802 \n",
            "Train Epochs: 4, Loss: 0.051582 \n",
            "Train Epochs: 4, Loss: 0.022882 \n",
            "Train Epochs: 4, Loss: 0.015284 \n",
            "Train Epochs: 4, Loss: 0.074570 \n",
            "Train Epochs: 4, Loss: 0.030160 \n",
            "Train Epochs: 4, Loss: 0.309896 \n",
            "Train Epochs: 4, Loss: 0.053120 \n",
            "Train Epochs: 4, Loss: 0.066005 \n",
            "Train Epochs: 4, Loss: 0.022319 \n",
            "Train Epochs: 4, Loss: 0.080289 \n",
            "Train Epochs: 4, Loss: 0.031441 \n",
            "Train Epochs: 4, Loss: 0.121398 \n",
            "Train Epochs: 4, Loss: 0.135378 \n",
            "Train Epochs: 4, Loss: 0.179700 \n",
            "Train Epochs: 4, Loss: 0.075639 \n",
            "Train Epochs: 4, Loss: 0.086380 \n",
            "Train Epochs: 4, Loss: 0.109689 \n",
            "Train Epochs: 4, Loss: 0.301443 \n",
            "Train Epochs: 4, Loss: 0.129563 \n",
            "Train Epochs: 4, Loss: 0.062464 \n",
            "Train Epochs: 4, Loss: 0.092377 \n",
            "Train Epochs: 4, Loss: 0.061143 \n",
            "Train Epochs: 4, Loss: 0.062038 \n",
            "Train Epochs: 4, Loss: 0.099816 \n",
            "Train Epochs: 4, Loss: 0.019777 \n",
            "Train Epochs: 4, Loss: 0.044103 \n",
            "Train Epochs: 4, Loss: 0.155065 \n",
            "Train Epochs: 4, Loss: 0.078461 \n",
            "Train Epochs: 4, Loss: 0.163562 \n",
            "Train Epochs: 4, Loss: 0.141004 \n",
            "Train Epochs: 4, Loss: 0.115505 \n",
            "Train Epochs: 4, Loss: 0.066359 \n",
            "Train Epochs: 4, Loss: 0.126272 \n",
            "Train Epochs: 4, Loss: 0.006850 \n",
            "Train Epochs: 4, Loss: 0.222678 \n",
            "Train Epochs: 4, Loss: 0.126428 \n",
            "Train Epochs: 4, Loss: 0.315700 \n",
            "Train Epochs: 4, Loss: 0.045679 \n",
            "Train Epochs: 4, Loss: 0.056161 \n",
            "Train Epochs: 4, Loss: 0.046841 \n",
            "Train Epochs: 4, Loss: 0.054434 \n",
            "Train Epochs: 4, Loss: 0.131334 \n",
            "Train Epochs: 4, Loss: 0.176872 \n",
            "Train Epochs: 4, Loss: 0.153493 \n",
            "Train Epochs: 4, Loss: 0.163463 \n",
            "Train Epochs: 4, Loss: 0.209145 \n",
            "Train Epochs: 4, Loss: 0.056021 \n",
            "Train Epochs: 4, Loss: 0.080327 \n",
            "Train Epochs: 4, Loss: 0.153350 \n",
            "Train Epochs: 4, Loss: 0.140320 \n",
            "Train Epochs: 4, Loss: 0.032786 \n",
            "Train Epochs: 4, Loss: 0.159238 \n",
            "\n",
            "Average Loss: 0.1532, Accuracy: 96\n",
            "Train Epochs: 5, Loss: 0.097063 \n",
            "Train Epochs: 5, Loss: 0.050881 \n",
            "Train Epochs: 5, Loss: 0.187035 \n",
            "Train Epochs: 5, Loss: 0.039146 \n",
            "Train Epochs: 5, Loss: 0.057397 \n",
            "Train Epochs: 5, Loss: 0.128399 \n",
            "Train Epochs: 5, Loss: 0.075640 \n",
            "Train Epochs: 5, Loss: 0.070625 \n",
            "Train Epochs: 5, Loss: 0.078424 \n",
            "Train Epochs: 5, Loss: 0.085495 \n",
            "Train Epochs: 5, Loss: 0.057165 \n",
            "Train Epochs: 5, Loss: 0.024729 \n",
            "Train Epochs: 5, Loss: 0.050641 \n",
            "Train Epochs: 5, Loss: 0.043156 \n",
            "Train Epochs: 5, Loss: 0.139406 \n",
            "Train Epochs: 5, Loss: 0.071362 \n",
            "Train Epochs: 5, Loss: 0.111283 \n",
            "Train Epochs: 5, Loss: 0.032577 \n",
            "Train Epochs: 5, Loss: 0.035751 \n",
            "Train Epochs: 5, Loss: 0.044956 \n",
            "Train Epochs: 5, Loss: 0.044905 \n",
            "Train Epochs: 5, Loss: 0.060251 \n",
            "Train Epochs: 5, Loss: 0.195737 \n",
            "Train Epochs: 5, Loss: 0.059202 \n",
            "Train Epochs: 5, Loss: 0.073495 \n",
            "Train Epochs: 5, Loss: 0.061702 \n",
            "Train Epochs: 5, Loss: 0.339294 \n",
            "Train Epochs: 5, Loss: 0.096326 \n",
            "Train Epochs: 5, Loss: 0.039391 \n",
            "Train Epochs: 5, Loss: 0.112282 \n",
            "Train Epochs: 5, Loss: 0.069584 \n",
            "Train Epochs: 5, Loss: 0.098548 \n",
            "Train Epochs: 5, Loss: 0.170079 \n",
            "Train Epochs: 5, Loss: 0.123898 \n",
            "Train Epochs: 5, Loss: 0.039721 \n",
            "Train Epochs: 5, Loss: 0.103895 \n",
            "Train Epochs: 5, Loss: 0.035421 \n",
            "Train Epochs: 5, Loss: 0.140279 \n",
            "Train Epochs: 5, Loss: 0.202044 \n",
            "Train Epochs: 5, Loss: 0.032368 \n",
            "Train Epochs: 5, Loss: 0.062120 \n",
            "Train Epochs: 5, Loss: 0.089062 \n",
            "Train Epochs: 5, Loss: 0.226110 \n",
            "Train Epochs: 5, Loss: 0.073750 \n",
            "Train Epochs: 5, Loss: 0.106412 \n",
            "Train Epochs: 5, Loss: 0.120084 \n",
            "Train Epochs: 5, Loss: 0.082459 \n",
            "Train Epochs: 5, Loss: 0.119791 \n",
            "Train Epochs: 5, Loss: 0.177789 \n",
            "Train Epochs: 5, Loss: 0.088550 \n",
            "Train Epochs: 5, Loss: 0.037523 \n",
            "Train Epochs: 5, Loss: 0.074075 \n",
            "Train Epochs: 5, Loss: 0.146682 \n",
            "Train Epochs: 5, Loss: 0.062668 \n",
            "Train Epochs: 5, Loss: 0.099833 \n",
            "Train Epochs: 5, Loss: 0.106206 \n",
            "Train Epochs: 5, Loss: 0.166250 \n",
            "Train Epochs: 5, Loss: 0.074316 \n",
            "Train Epochs: 5, Loss: 0.161626 \n",
            "Train Epochs: 5, Loss: 0.084330 \n",
            "\n",
            "Average Loss: 0.1732, Accuracy: 97\n",
            "Train Epochs: 6, Loss: 0.016816 \n",
            "Train Epochs: 6, Loss: 0.107394 \n",
            "Train Epochs: 6, Loss: 0.003978 \n",
            "Train Epochs: 6, Loss: 0.103180 \n",
            "Train Epochs: 6, Loss: 0.033306 \n",
            "Train Epochs: 6, Loss: 0.221522 \n",
            "Train Epochs: 6, Loss: 0.014850 \n",
            "Train Epochs: 6, Loss: 0.045275 \n",
            "Train Epochs: 6, Loss: 0.140740 \n",
            "Train Epochs: 6, Loss: 0.013785 \n",
            "Train Epochs: 6, Loss: 0.003090 \n",
            "Train Epochs: 6, Loss: 0.054843 \n",
            "Train Epochs: 6, Loss: 0.091022 \n",
            "Train Epochs: 6, Loss: 0.049111 \n",
            "Train Epochs: 6, Loss: 0.038069 \n",
            "Train Epochs: 6, Loss: 0.033867 \n",
            "Train Epochs: 6, Loss: 0.021544 \n",
            "Train Epochs: 6, Loss: 0.102351 \n",
            "Train Epochs: 6, Loss: 0.068123 \n",
            "Train Epochs: 6, Loss: 0.129123 \n",
            "Train Epochs: 6, Loss: 0.190711 \n",
            "Train Epochs: 6, Loss: 0.182613 \n",
            "Train Epochs: 6, Loss: 0.027788 \n",
            "Train Epochs: 6, Loss: 0.137331 \n",
            "Train Epochs: 6, Loss: 0.056449 \n",
            "Train Epochs: 6, Loss: 0.166320 \n",
            "Train Epochs: 6, Loss: 0.083403 \n",
            "Train Epochs: 6, Loss: 0.110861 \n",
            "Train Epochs: 6, Loss: 0.024673 \n",
            "Train Epochs: 6, Loss: 0.105623 \n",
            "Train Epochs: 6, Loss: 0.021726 \n",
            "Train Epochs: 6, Loss: 0.068817 \n",
            "Train Epochs: 6, Loss: 0.074708 \n",
            "Train Epochs: 6, Loss: 0.128635 \n",
            "Train Epochs: 6, Loss: 0.062836 \n",
            "Train Epochs: 6, Loss: 0.067838 \n",
            "Train Epochs: 6, Loss: 0.082080 \n",
            "Train Epochs: 6, Loss: 0.093572 \n",
            "Train Epochs: 6, Loss: 0.130217 \n",
            "Train Epochs: 6, Loss: 0.058179 \n",
            "Train Epochs: 6, Loss: 0.172974 \n",
            "Train Epochs: 6, Loss: 0.015783 \n",
            "Train Epochs: 6, Loss: 0.103404 \n",
            "Train Epochs: 6, Loss: 0.062619 \n",
            "Train Epochs: 6, Loss: 0.038131 \n",
            "Train Epochs: 6, Loss: 0.084163 \n",
            "Train Epochs: 6, Loss: 0.121098 \n",
            "Train Epochs: 6, Loss: 0.074731 \n",
            "Train Epochs: 6, Loss: 0.053007 \n",
            "Train Epochs: 6, Loss: 0.017409 \n",
            "Train Epochs: 6, Loss: 0.028734 \n",
            "Train Epochs: 6, Loss: 0.149960 \n",
            "Train Epochs: 6, Loss: 0.153425 \n",
            "Train Epochs: 6, Loss: 0.039504 \n",
            "Train Epochs: 6, Loss: 0.098821 \n",
            "Train Epochs: 6, Loss: 0.049506 \n",
            "Train Epochs: 6, Loss: 0.145180 \n",
            "Train Epochs: 6, Loss: 0.009380 \n",
            "Train Epochs: 6, Loss: 0.077246 \n",
            "Train Epochs: 6, Loss: 0.198399 \n",
            "\n",
            "Average Loss: 0.1679, Accuracy: 96\n",
            "Train Epochs: 7, Loss: 0.041444 \n",
            "Train Epochs: 7, Loss: 0.094461 \n",
            "Train Epochs: 7, Loss: 0.141821 \n",
            "Train Epochs: 7, Loss: 0.015918 \n",
            "Train Epochs: 7, Loss: 0.215893 \n",
            "Train Epochs: 7, Loss: 0.070775 \n",
            "Train Epochs: 7, Loss: 0.105638 \n",
            "Train Epochs: 7, Loss: 0.082140 \n",
            "Train Epochs: 7, Loss: 0.025946 \n",
            "Train Epochs: 7, Loss: 0.011614 \n",
            "Train Epochs: 7, Loss: 0.064014 \n",
            "Train Epochs: 7, Loss: 0.175320 \n",
            "Train Epochs: 7, Loss: 0.134336 \n",
            "Train Epochs: 7, Loss: 0.020805 \n",
            "Train Epochs: 7, Loss: 0.070404 \n",
            "Train Epochs: 7, Loss: 0.009985 \n",
            "Train Epochs: 7, Loss: 0.034536 \n",
            "Train Epochs: 7, Loss: 0.010843 \n",
            "Train Epochs: 7, Loss: 0.100737 \n",
            "Train Epochs: 7, Loss: 0.098424 \n",
            "Train Epochs: 7, Loss: 0.258829 \n",
            "Train Epochs: 7, Loss: 0.030294 \n",
            "Train Epochs: 7, Loss: 0.016364 \n",
            "Train Epochs: 7, Loss: 0.048486 \n",
            "Train Epochs: 7, Loss: 0.139028 \n",
            "Train Epochs: 7, Loss: 0.025222 \n",
            "Train Epochs: 7, Loss: 0.065177 \n",
            "Train Epochs: 7, Loss: 0.049262 \n",
            "Train Epochs: 7, Loss: 0.089272 \n",
            "Train Epochs: 7, Loss: 0.010398 \n",
            "Train Epochs: 7, Loss: 0.197335 \n",
            "Train Epochs: 7, Loss: 0.178095 \n",
            "Train Epochs: 7, Loss: 0.102910 \n",
            "Train Epochs: 7, Loss: 0.113291 \n",
            "Train Epochs: 7, Loss: 0.015335 \n",
            "Train Epochs: 7, Loss: 0.056208 \n",
            "Train Epochs: 7, Loss: 0.073230 \n",
            "Train Epochs: 7, Loss: 0.060647 \n",
            "Train Epochs: 7, Loss: 0.037676 \n",
            "Train Epochs: 7, Loss: 0.035833 \n",
            "Train Epochs: 7, Loss: 0.180743 \n",
            "Train Epochs: 7, Loss: 0.062928 \n",
            "Train Epochs: 7, Loss: 0.082554 \n",
            "Train Epochs: 7, Loss: 0.052751 \n",
            "Train Epochs: 7, Loss: 0.087273 \n",
            "Train Epochs: 7, Loss: 0.020312 \n",
            "Train Epochs: 7, Loss: 0.086770 \n",
            "Train Epochs: 7, Loss: 0.033397 \n",
            "Train Epochs: 7, Loss: 0.020537 \n",
            "Train Epochs: 7, Loss: 0.070713 \n",
            "Train Epochs: 7, Loss: 0.019982 \n",
            "Train Epochs: 7, Loss: 0.131054 \n",
            "Train Epochs: 7, Loss: 0.009257 \n",
            "Train Epochs: 7, Loss: 0.099287 \n",
            "Train Epochs: 7, Loss: 0.103484 \n",
            "Train Epochs: 7, Loss: 0.105517 \n",
            "Train Epochs: 7, Loss: 0.314243 \n",
            "Train Epochs: 7, Loss: 0.226741 \n",
            "Train Epochs: 7, Loss: 0.181231 \n",
            "Train Epochs: 7, Loss: 0.103383 \n",
            "\n",
            "Average Loss: 0.1738, Accuracy: 96\n",
            "Train Epochs: 8, Loss: 0.028401 \n",
            "Train Epochs: 8, Loss: 0.031307 \n",
            "Train Epochs: 8, Loss: 0.077782 \n",
            "Train Epochs: 8, Loss: 0.078672 \n",
            "Train Epochs: 8, Loss: 0.056784 \n",
            "Train Epochs: 8, Loss: 0.171153 \n",
            "Train Epochs: 8, Loss: 0.167901 \n",
            "Train Epochs: 8, Loss: 0.079707 \n",
            "Train Epochs: 8, Loss: 0.096406 \n",
            "Train Epochs: 8, Loss: 0.022096 \n",
            "Train Epochs: 8, Loss: 0.005508 \n",
            "Train Epochs: 8, Loss: 0.051960 \n",
            "Train Epochs: 8, Loss: 0.021522 \n",
            "Train Epochs: 8, Loss: 0.110111 \n",
            "Train Epochs: 8, Loss: 0.062568 \n",
            "Train Epochs: 8, Loss: 0.116686 \n",
            "Train Epochs: 8, Loss: 0.105060 \n",
            "Train Epochs: 8, Loss: 0.215046 \n",
            "Train Epochs: 8, Loss: 0.055631 \n",
            "Train Epochs: 8, Loss: 0.044795 \n",
            "Train Epochs: 8, Loss: 0.111035 \n",
            "Train Epochs: 8, Loss: 0.027969 \n",
            "Train Epochs: 8, Loss: 0.024357 \n",
            "Train Epochs: 8, Loss: 0.057774 \n",
            "Train Epochs: 8, Loss: 0.027964 \n",
            "Train Epochs: 8, Loss: 0.045968 \n",
            "Train Epochs: 8, Loss: 0.006102 \n",
            "Train Epochs: 8, Loss: 0.084928 \n",
            "Train Epochs: 8, Loss: 0.024932 \n",
            "Train Epochs: 8, Loss: 0.082245 \n",
            "Train Epochs: 8, Loss: 0.196183 \n",
            "Train Epochs: 8, Loss: 0.042569 \n",
            "Train Epochs: 8, Loss: 0.048240 \n",
            "Train Epochs: 8, Loss: 0.050334 \n",
            "Train Epochs: 8, Loss: 0.026530 \n",
            "Train Epochs: 8, Loss: 0.032332 \n",
            "Train Epochs: 8, Loss: 0.108138 \n",
            "Train Epochs: 8, Loss: 0.028582 \n",
            "Train Epochs: 8, Loss: 0.042013 \n",
            "Train Epochs: 8, Loss: 0.057124 \n",
            "Train Epochs: 8, Loss: 0.044224 \n",
            "Train Epochs: 8, Loss: 0.069840 \n",
            "Train Epochs: 8, Loss: 0.055875 \n",
            "Train Epochs: 8, Loss: 0.052233 \n",
            "Train Epochs: 8, Loss: 0.038319 \n",
            "Train Epochs: 8, Loss: 0.093944 \n",
            "Train Epochs: 8, Loss: 0.084596 \n",
            "Train Epochs: 8, Loss: 0.033597 \n",
            "Train Epochs: 8, Loss: 0.018263 \n",
            "Train Epochs: 8, Loss: 0.005869 \n",
            "Train Epochs: 8, Loss: 0.002036 \n",
            "Train Epochs: 8, Loss: 0.049650 \n",
            "Train Epochs: 8, Loss: 0.053583 \n",
            "Train Epochs: 8, Loss: 0.086068 \n",
            "Train Epochs: 8, Loss: 0.093380 \n",
            "Train Epochs: 8, Loss: 0.030992 \n",
            "Train Epochs: 8, Loss: 0.040476 \n",
            "Train Epochs: 8, Loss: 0.018810 \n",
            "Train Epochs: 8, Loss: 0.061156 \n",
            "Train Epochs: 8, Loss: 0.116097 \n",
            "\n",
            "Average Loss: 0.1632, Accuracy: 97\n",
            "Train Epochs: 9, Loss: 0.023825 \n",
            "Train Epochs: 9, Loss: 0.206605 \n",
            "Train Epochs: 9, Loss: 0.003475 \n",
            "Train Epochs: 9, Loss: 0.023236 \n",
            "Train Epochs: 9, Loss: 0.042519 \n",
            "Train Epochs: 9, Loss: 0.105387 \n",
            "Train Epochs: 9, Loss: 0.055256 \n",
            "Train Epochs: 9, Loss: 0.108133 \n",
            "Train Epochs: 9, Loss: 0.070912 \n",
            "Train Epochs: 9, Loss: 0.137716 \n",
            "Train Epochs: 9, Loss: 0.113260 \n",
            "Train Epochs: 9, Loss: 0.228627 \n",
            "Train Epochs: 9, Loss: 0.018200 \n",
            "Train Epochs: 9, Loss: 0.018181 \n",
            "Train Epochs: 9, Loss: 0.042025 \n",
            "Train Epochs: 9, Loss: 0.031885 \n",
            "Train Epochs: 9, Loss: 0.030553 \n",
            "Train Epochs: 9, Loss: 0.016276 \n",
            "Train Epochs: 9, Loss: 0.015963 \n",
            "Train Epochs: 9, Loss: 0.048991 \n",
            "Train Epochs: 9, Loss: 0.036661 \n",
            "Train Epochs: 9, Loss: 0.089798 \n",
            "Train Epochs: 9, Loss: 0.072015 \n",
            "Train Epochs: 9, Loss: 0.010514 \n",
            "Train Epochs: 9, Loss: 0.069532 \n",
            "Train Epochs: 9, Loss: 0.055623 \n",
            "Train Epochs: 9, Loss: 0.039496 \n",
            "Train Epochs: 9, Loss: 0.020984 \n",
            "Train Epochs: 9, Loss: 0.083290 \n",
            "Train Epochs: 9, Loss: 0.034843 \n",
            "Train Epochs: 9, Loss: 0.005782 \n",
            "Train Epochs: 9, Loss: 0.028308 \n",
            "Train Epochs: 9, Loss: 0.046334 \n",
            "Train Epochs: 9, Loss: 0.188895 \n",
            "Train Epochs: 9, Loss: 0.014287 \n",
            "Train Epochs: 9, Loss: 0.081167 \n",
            "Train Epochs: 9, Loss: 0.171802 \n",
            "Train Epochs: 9, Loss: 0.053656 \n",
            "Train Epochs: 9, Loss: 0.130630 \n",
            "Train Epochs: 9, Loss: 0.084604 \n",
            "Train Epochs: 9, Loss: 0.153196 \n",
            "Train Epochs: 9, Loss: 0.173296 \n",
            "Train Epochs: 9, Loss: 0.087067 \n",
            "Train Epochs: 9, Loss: 0.097875 \n",
            "Train Epochs: 9, Loss: 0.038748 \n",
            "Train Epochs: 9, Loss: 0.055122 \n",
            "Train Epochs: 9, Loss: 0.030710 \n",
            "Train Epochs: 9, Loss: 0.038581 \n",
            "Train Epochs: 9, Loss: 0.067115 \n",
            "Train Epochs: 9, Loss: 0.027406 \n",
            "Train Epochs: 9, Loss: 0.068109 \n",
            "Train Epochs: 9, Loss: 0.164088 \n",
            "Train Epochs: 9, Loss: 0.110257 \n",
            "Train Epochs: 9, Loss: 0.064761 \n",
            "Train Epochs: 9, Loss: 0.091284 \n",
            "Train Epochs: 9, Loss: 0.056659 \n",
            "Train Epochs: 9, Loss: 0.077640 \n",
            "Train Epochs: 9, Loss: 0.096230 \n",
            "Train Epochs: 9, Loss: 0.076052 \n",
            "Train Epochs: 9, Loss: 0.010806 \n",
            "\n",
            "Average Loss: 0.1726, Accuracy: 97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### predict"
      ],
      "metadata": {
        "id": "2iCKQhka5cGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "images, labels = next(iter(validation_loader))# load an image from validation_loader\n",
        "img = images[0].view(1, 784) \n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.numpy()[0])\n",
        "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
        "img = np.array(img, dtype='float')\n",
        "pixels = img.reshape((28, 28))\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "11Qge0PVWlG0",
        "outputId": "ee0fa33e-bd4c-4b9d-c46d-03201ed16199"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Digit = 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}